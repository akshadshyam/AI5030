\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{\textbf{Assignment 2}}
\author{Akshad Shyam}
\date{17 March 2022}

\begin{document}

\maketitle

\textbf{Q.108 UGC 2017} \\
Let $X_{1},X_{2},....,X_{n}$ be a random sample from $f_{\theta}(x)$, a probability density function or a probability mass function. Defined \\

$s^{2}_{n} = \frac{\sum_{n=1}^{n}(X_{i} - \overline{X})^{2}} {n-1}$,{\hspace{0.2cm}} $\overline{X}_{n} = \frac{\sum_{i=1}^{n}X_{i}}{n}$ \\

Then $s^{2}_{n}$ is unbiased for ${\theta}$ if \\ 
1) $f_{\theta}(x) = \frac{e^{-\theta}{\theta}^{x}}{x!} ; x>0$ \\
2) $f_{\theta}(x) = \frac{e^{\frac{-x^{2}}{2{\theta}}}}{\sqrt{2\pi\theta}} -\infty<x<\infty,\theta>0$ \\
3) $f_{\theta}(x) = \frac{e^{\frac{-x}{\theta}}}{\theta} x>0,\theta>0$ \\
4) $f_{\theta}(x) = {\theta}e^{-{\theta}x} x>0, \theta>0 $

Answer: Option 1 and Option 2 are correct.

\section{Solution}
Regardless of the distribution, the expected value of the sample variance is equal to the population variance. Hence the sample variance is said to be an unbiased estimator of population variance.
\begin{equation} \label{eq1}
    E[s^{2}] = \sigma^{2}
\end{equation}

\textbf{Proof:} \\
Let $X_{1},X_{2}...,X_{n}$ be n independent observations from a population with mean $\mu$ and variance $\sigma^{2}$ \\
\begin{equation} \label{eq2}
    E[\sum{X_{i}}] = \sum{E[X_{i]}} 
\end{equation}

\begin{equation}\label{eq3}
 E[cX] = cE[X] \\
\end{equation}
We also know that,
\begin{equation}\label{eq4}
    \sigma^{2} = E[X^{2}] - E[X]^{2};{\hspace{0.2cm}} E[X^{2}] = \sigma^{2} + \mu^{2} \\
\end{equation}


If we take n samples from this population, then the sample mean would be $\mu$ and sample variance would be $\frac{\sigma^{2}}{n}$. Then, according to \ref{eq4}, \\
\begin{equation} \label{eq5}
    E[\overline{X}^{2}] = \frac{\sigma^{2}}{n} + \mu^{2}\\
\end{equation}
Now, 
\begin{gather*}
   E [s^{2}_{n}] = E[\frac{\sum_{n=1}^{n}(X_{i} - \overline{X})^{2}} {n-1}] \\
    \vspace{0.1cm}
    E[\sum_{n=1}^{n}(X_{i} - \overline{X})^{2}] = E[\sum(X_{i}^{2}-2X_{i}\overline{X} + \overline{X}^{2})] \\ \vspace{0.1cm}
    = E[\sum(X_{i}^{2}) - 2\overline{X}\sum(X_{i})+\sum(\overline{X}^{2})] \\
    \vspace{0.1cm}
    = E[\sum(X_{i}^{2}) - 2\overline{X}n\overline{X} + n\overline{X}^{2}] \\
    \vspace{0.1cm}
    = E[\sum(X_{i}^{2}) - n\overline{X}^{2}] \\
    \vspace{0.1cm}
    = [\sum(E[X_{i}^{2}]) - E[n\overline{X}^{2}]] \\
    \vspace{0.1cm}
\end{gather*}
Now, substituting \ref{eq4} and \ref{eq5}, \\
\begin{align*}
    = [\sum(\sigma^{2}+\mu^{2}) - n(\frac{\sigma^{2}}{n} + \mu^{2})] \\
    \vspace{0.1cm}
    = [n\sigma^{2} + {n\mu^{2}} - \sigma^{2} - {n\mu^{2}}] = (n-1)\sigma^{2} \\
    \vspace{0.1cm}
\end{align*}
\begin{equation}
     E [s^{2}_{n}] = \frac{(n-1)\sigma^{2}}{(n-1)} = \sigma^{2}\\
\end{equation}
\textbf{Hence the sample variance is said to be an unbiased estimator of the population variance.}
\section{Checking Options}
To check if $s_{n}^{2}$ is an unbiased estimator of $\theta$, $\theta$ should be the population variance of the distribution
\subsection{Option 1}
$f_{\theta}(x) = \frac{e^{-\theta}{\theta}^{x}}{x!}$ \\
This is a probability distribution following poisson distribution \\ 
Mean = E[X] = $\theta$ \\
Variance = $E[X^{2}] - [E[X]]^{2} $\\

\begin{align*}
    E[X^{2}] = \sum{x^{2}P(X=x)}\\   
    = \sum{x^{2}\frac{e^{-\theta}{\theta}^{x}}{x!}} \\
    = \sum{x\frac{e^{-\theta}{\theta}^{x}}{(x-1)!}} \\
    = {\theta}e^{-\theta}[\sum{x\frac{\theta^{x-1}}{(x-1)!}}] \\ 
    = {\theta}e^{-\theta}[\sum{(x-1)\frac{\theta^{x-1}}{(x-1)!}} + \sum{(1)\frac{\theta^{x-1}}{(x-1)!}}] \\ 
    = {\theta}e^{-\theta}[{\theta}[\sum{\frac{\theta^{x-2}}{(x-2)!}}] + \sum{(1)\frac{\theta^{x-1}}{(x-1)!}}] \\
\end{align*}
According to taylor series expansion,
\begin{align*}
    = {\theta}e^{-\theta}[{\theta}[e^{\theta}] + e^{\theta}]
    = \theta^{2} + \theta \\
    Variance = \theta^{2} + \theta - (\theta)^{2} = \theta
\end{align*}

Hence Option 1 is correct

\subsection{Option 2}
$f_{\theta}(x) = \frac{e^{\frac{-x^{2}}{2{\theta}}}}{\sqrt{2\pi\theta}}$ \\
Option 2 is a probability distribution function following the normal distribution.\\

Mean = 0; Variance = $E[X^{2}] - [E[X]]^{2} = E[X^{2}]$\\
\begin{align*}
 E[X^{2}] =  \int_{-\infty}^{\infty}{x^{2}f(x)\mathrm{d}x}   \\
          = \int_{-\infty}^{\infty}{x^{2}\frac{e^{\frac{-x^{2}}{2{\theta}}}}{\sqrt{2\pi\theta}}\mathrm{d}x} \\
          = \frac{1}{\sqrt{2\pi\theta}}\int_{-\infty}^{\infty}{x^{2}{e^{\frac{-x^{2}}{2\sqrt{{\theta}^{2}}}}}\mathrm{d}x}\\
\end{align*}
Taking $z = \frac{x^{2}}{2\theta}; x\mathrm{d}x = \theta\mathrm{d}z$\\
\begin{align*}
    = \frac{1}{\sqrt{2\pi\theta}}\int_{-\infty}^{\infty}{\sqrt{2{\theta}z}{e^{-z}}\theta\mathrm{d}z} \\
    = \frac{2\theta}{\sqrt{\pi}}\int_{0}^{\infty}{\sqrt{z}{e^{-z}}\mathrm{d}z} %(Normal distribution is symmetric)%\\
\end{align*}
According to gamma function, $\Gamma(x) = \int{z^{x-1}e^{-z}\mathrm{d}z}$\\
Since x = 3/2 here $\Gamma(n/2) = \frac{(n-2)!!\sqrt{\pi}}{2^{\frac{n-1}{2}}} = \sqrt{\pi}/2$\\
Substituting this value,\\
\begin{align*}
    \frac{2\theta}{\sqrt{\pi}}\times\frac{\sqrt{\pi}}{2} \\ = \theta
\end{align*}

Hence Option 2 is correct
\subsection{Option 3}

$f_{\theta}(x) = \frac{e^{\frac{-x}{\theta}}}{\theta}$ \\
Option 3 is a probability distribution function following the exponential distribution.\\
Mean = $E[X]$
\begin{align*}
    E[X] = \int_{0}^{\infty}{x}\frac{e^{\frac{-x}{\theta}}}{\theta}\mathrm{d}x \\
\end{align*}
Taking $y = \frac{x}{\theta}; \mathrm{d}x = \theta\mathrm{d}y$ 
\begin{align*}
    = \theta\int_{0}^{\infty}{y{e^{-y}}\mathrm{d}y} \\
    = \theta[-ye^{-y} -e^{-y}]_{0}^{\infty} = \theta
\end{align*}
Variance = $E[X^{2}] - [E[X]]^{2}$\\
\begin{align*}
    E[X^{2}] = \int_{0}^{\infty}{x^{2}}\frac{e^{\frac{-x}{\theta}}}{\theta}\mathrm{d}x \\
\end{align*}
Taking $y = \frac{x}{\theta}; \mathrm{d}x = \theta\mathrm{d}y$
\begin{align*}
    = \theta^{2}\int_{0}^{\infty}{y^{2}e^{-y}}\mathrm{d}y \\
    = \theta^{2}[-y^{2}e^{-y} -2ye^{-y} -2e^{-y}]_{0}^{\infty} = 2\theta^{2}\\
    Variance = 2\theta^{2} - {\theta}^{2} = \theta^{2}\\
\end{align*}
Option 3 is incorrect.
\subsection{Option 4}

 $f_{\theta}(x) = {\theta}e^{-{\theta}x}$ \\
Option 4 is a probability distribution function following exponential distribution. \\
Mean = $E[X]$
\begin{align*}
    E[X] = \int_{0}^{\infty}{x}{\theta}e^{-{\theta}x}\mathrm{d}x \\
\end{align*}
Taking $y = {x}{\theta}; \mathrm{d}x = \frac{\mathrm{d}y}{\theta}$ \\
\begin{align*}
    = \frac{1}{\theta}\int_{0}^{\infty}{y{e^{-y}}\mathrm{d}y} \\
    = \frac{1}{\theta}[-ye^{-y} -e^{-y}]_{0}^{\infty} = \frac{1}{\theta}
\end{align*}
Variance = $E[X^{2}] - [E[X]]^{2}$\\
\begin{align*}
    E[X^{2}] = \int_{0}^{\infty}{x^{2}}{\theta}e^{-{\theta}x}\mathrm{d}x \\
\end{align*}
Taking $y = {x}{\theta}; \mathrm{d}x = \frac{\mathrm{d}y}{\theta}$ \\
\begin{align*}
    = \frac{1}{\theta^{2}}\int_{0}^{\infty}{y^{2}e^{-y}}\mathrm{d}y \\
    = \frac{1}{\theta^{2}}[-y^{2}e^{-y} -2ye^{-y} -2e^{-y}]_{0}^{\infty} = \frac{2}{\theta^{2}}\\
    Variance = \frac{2}{\theta^{2}} - \frac{1}{\theta^{2}} = \frac{1}{\theta^{2}}\\
\end{align*}

Option 4 is incorrect

\end{document}
